# ğŸ§  AI Avatar Chat â€“ Voice-to-Avatar Conversational System

An interactive **AI avatar web application** that listens to user voice, understands the message using **Whisper ASR**, generates intelligent text replies using **Gemini AI**, and speaks back using **gtts** voice synthesis.  
The system also generates a **lip-synced avatar video** that visually responds to the user.

---

## ğŸš€ Features

âœ… Voice-to-Text via **Whisper ASR**  
âœ… Text Intelligence using **Gemini Live API**  
âœ… Realistic Text-to-Speech via **GTTS**  
âœ… Lip-Synced Avatar Response via **LipSync**  
âœ… Secure Login & Registration (FastAPI + MongoDB)  
âœ… Modern Frontend built with **React + TypeScript**  
âœ… Full Audio/Video Interaction Cycle  
âœ… CORS-enabled backend (`http://localhost:8080`)  

---

## ğŸ—ï¸ Project Architecture

```plaintext
ğŸ¤ User speaks
   â†“
ğŸ§ Frontend (React)
   - Records voice (Web Audio API)
   - Sends to FastAPI backend with credentials
   â†“
âš™ï¸ FastAPI Backend
   - Authenticates user (HTTPBasic)
   - Transcribes audio (Whisper)
   - Generates response (Gemini API)
   - Converts to speech (gtts)
   - Creates lip-sync video (LipSync)
   â†“
ğŸ§‘â€ğŸ’» MongoDB
   - Stores user credentials & avatars
   â†“
ğŸ¬ Frontend
   - Displays avatar video
   - Shows chat history and messages
ğŸ§© Technologies Used
Component	Technology
Frontend	React + TypeScript + TailwindCSS
Backend	FastAPI (Python)
Database	MongoDB (pymongo)
AI Text Model	Gemini Live API
Speech-to-Text	Whisper
Text-to-Speech	gtts
Avatar Lip Sync	LipSync
Authentication	HTTPBasic & MongoDB
Deployment	Uvicorn / Render / Vercel (optional)

ğŸ› ï¸ Installation Guide
1ï¸âƒ£ Clone the Repository
bash
Copy code
git clone https://github.com/your-username/ai-avatar-chat.git
cd ai-avatar-chat
2ï¸âƒ£ Backend Setup (FastAPI)
ğŸ Create Virtual Environment
bash
Copy code
python -m venv venv
source venv/bin/activate  # macOS/Linux
venv\Scripts\activate     # Windows
ğŸ“¦ Install Dependencies
bash
Copy code
pip install fastapi uvicorn pymongo whisper pyttsx3 gtts google-generativeai lipsync certifi python-multipart
âš™ï¸ Set Environment Variables
Create a .env file inside your backend directory:

bash
Copy code
OPENAI_API_KEY=your_openai_api_key
GOOGLE_API_KEY=your_gemini_api_key
MONGO_URI=your_mongodb_connection_string
â–¶ï¸ Run FastAPI Server
bash
Copy code
uvicorn main:app --reload
Backend runs on:
ğŸ‘‰ http://localhost:8000

3ï¸âƒ£ Frontend Setup (React + Vite or Next.js)
bash
Copy code
cd frontend
npm install
npm run dev
Frontend runs on:
ğŸ‘‰ http://localhost:8080

ğŸ”— API Endpoints
Endpoint	Method	Description
/register	POST	Register a new user (FormData: username, password, image)
/upload-audio	POST	Upload recorded audio and get AI response
/get-video	GET	Fetch the latest avatar response video
/login	POST	(Optional) Login endpoint for authentication


ğŸ’¬ Example Flow
User registers with a username, password, and optional image.

Frontend records audio and sends it to /upload-audio.

FastAPI:

Transcribes with Whisper

Generates text with Gemini API

Converts text to speech using gtts

Creates a lip-synced avatar video

Frontend displays the avatar and the AIâ€™s spoken response.

ğŸ” Authentication
Uses HTTP Basic Auth for secure communication between frontend and backend.

User credentials are stored in MongoDB.

Each request (like /upload-audio) must include:

js
Copy code
Authorization: Basic base64(username:password)
ğŸ§  Gemini AI Integration (Text Generation)
python
Copy code
import google.generativeai as genai
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

def call_llm_sync(prompt: str) -> str:
    model = genai.GenerativeModel("gemini-1.5-flash")
    response = model.generate_content(prompt)
    return response.text
ğŸ”Š gtts Integration
python
Copy code
from quick_tts import text_to_speech

def generate_tts_response(text: str, output_path: str = "static/output.wav"):
    text_to_speech(
        text=text,
        output_file=output_path,
        model="tts-1-hd",
        voice="nova"
    )
    return output_path
ğŸ¨ Frontend Components Overview
Component	Purpose
AuthModal.tsx	Handles signup/login
AvatarDisplay.tsx	Displays avatar & video
ChatInterface.tsx	Chat message interface
VoiceRecorder.tsx	Records and sends audio
index.tsx	Main app controller

ğŸ§© CORS Configuration
Enabled in backend to allow frontend:

python
Copy code
from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:8080"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
ğŸ§¾ Folder Structure
arduino
Copy code
ğŸ“¦ ai-avatar-chat
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â””â”€â”€ README.md
ğŸ§ª Testing
Run Backend Tests
bash
Copy code
pytest
Run Frontend in Development
bash
Copy code
npm run dev
ğŸš¢ Deployment
You can deploy:

Backend  AWS EC2

Frontend S3

Make sure to set environment variables in your host settings.

ğŸ§‘â€ğŸ’» Author
Ankur Yadav
AI-DS Engineer (React + Django + FastAPI)

ğŸŒ GitHub: https://github.com/ankur-06-2003

ğŸ“œ License
This project is licensed under the MIT License â€” youâ€™re free to use, modify, and distribute it.

â¤ï¸ Acknowledgments
FastAPI

Google Gemini API

gtts

Whisper

LipSync

yaml
Copy code

---

Would you like me to include **architecture diagram (flowchart in Markdown or PNG)** inside this README (so it visually shows the data flow between React â†’ FastAPI â†’ Gemini â†’ TTS â†’ LipSync â†’ Frontend)?






according to file





ChatGPT can make mistakes. Check important info. See Cookie Preferences.
